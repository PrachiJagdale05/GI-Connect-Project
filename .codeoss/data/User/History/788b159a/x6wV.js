// --- FINAL VERSION WITH SPECIALIZED IMAGE SEGMENTATION ---
import express from "express";
import cors from "cors";
import fetch from "node-fetch";
import { createClient } from "@supabase/supabase-js";
import { GoogleAuth } from "google-auth-library";
import { Buffer } from "buffer";

// --------- App + basic middleware ----------
const app = express();
app.use(express.json({ limit: "15mb" }));
app.use(cors({ origin: process.env.CORS_ORIGIN || "*" }));

console.log("vendor-ai-worker starting", {
  node: process.version,
  cwd: process.cwd(),
});

// --------- ENV (strict names) ----------
const PORT = Number(process.env.PORT || 8080);
const WORKER_SECRET = process.env.WORKER_SHARED_SECRET;
const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
const SUPABASE_BUCKET = process.env.SUPABASE_BUCKET || "generated-images";
const PROJECT_ID = process.env.VERTEX_PROJECT_ID || process.env.GCP_PROJECT || process.env.GCP_PROJECT_ID;
const LOCATION = process.env.VERTEX_LOCATION || "us-central1";
const VISION_MODEL = process.env.VISION_MODEL_NAME || "gemini-1.5-flash-001"; 
const IMAGE_MODEL = process.env.IMAGE_MODEL_NAME || "imagegeneration@006";
// NEW: Dedicated model for creating the mask
const SEGMENTATION_MODEL = process.env.SEGMENTATION_MODEL_NAME || "image-segmentation@001";
const MAX_IMAGES = Math.min(Number(process.env.MAX_GENERATED_IMAGES || 4), 8);
const REGION_BASE = `https://${LOCATION}-aiplatform.googleapis.com/v1`;

// --------- minimal runtime guards ----------
const missing = [];
if (!SUPABASE_URL) missing.push("SUPABASE_URL");
if (!SUPABASE_SERVICE_ROLE_KEY) missing.push("SUPABASE_SERVICE_ROLE_KEY");
if (!PROJECT_ID) missing.push("VERTEX_PROJECT_ID");
if (!VISION_MODEL) missing.push("VISION_MODEL_NAME");
if (!IMAGE_MODEL) missing.push("IMAGE_MODEL_NAME");
if (!SEGMENTATION_MODEL) missing.push("SEGMENTATION_MODEL_NAME");
if (!WORKER_SECRET) missing.push("WORKER_SHARED_SECRET");

if (missing.length) {
  console.error("CRITICAL: Missing required env vars, worker will not be fully functional:", missing.join(", "));
}

// --------- clients ----------
let supabase = null;
try {
  if (SUPABASE_URL && SUPABASE_SERVICE_ROLE_KEY) {
    supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);
    console.log("Supabase client ready.");
  }
} catch (e) { console.error("Supabase init failed:", e); }

const auth = new GoogleAuth({ scopes: ["https://www.googleapis.com/auth/cloud-platform"] });

// --------- Helper Functions (unchanged) ----------
async function getAccessToken() { /* ... */ }
function tryParseJson(str) { /* ... */ }
async function uploadBase64ToSupabase(base64OrDataUri, pathFilename) { /* ... */ }

// --------- AI Model Callers ----------

async function callVisionGenerate(imageBase64, productName) { /* ... */ }

// --- NEW, RELIABLE MASK GENERATION FUNCTION ---
async function callSegmentationModel(imageBase64) {
    console.log("Generating product mask using dedicated Segmentation model...");
    const accessToken = await getAccessToken();
    const url = `${REGION_BASE}/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${SEGMENTATION_MODEL}:predict`;

    const body = {
        instances: [{
            "image": { "bytesBase64Encoded": imageBase64 }
        }],
        parameters: {
            // This parameter asks the model to identify the most prominent object
            "maskType": "FOREGROUND"
        }
    };

    const resp = await fetch(url, { method: "POST", headers: { Authorization: `Bearer ${accessToken}`, "Content-Type": "application/json" }, body: JSON.stringify(body) });
    const text = await resp.text();
    if (!resp.ok) { throw new Error(`Segmentation failed: ${resp.status} ${text}`); }

    const json = JSON.parse(text);
    // The segmentation model returns a guaranteed-valid Base64 PNG in this field
    const maskBase64 = json.predictions[0]?.categoryMask;

    if (!maskBase64) {
        throw new Error("Segmentation model did not return a valid mask.");
    }
    
    console.log("Successfully generated mask with segmentation model.");
    return maskBase64;
}


async function callInpaintingWithMask(imageBase64, maskBase64, prompt, sampleCount) { /* ... */ }

// --------- Main Orchestration Route ----------
app.get("/", (req, res) => res.send("vendor-ai-worker is running ðŸš€"));
app.post("/orchestrate", async (req, res) => {
  try {
    // ... (Initial checks are the same) ...
    const { image_url: imageUrl, product_name: productName, maker_id } = req.body || {};
    if (!imageUrl || !productName) {
      return res.status(400).json({ error: "image_url and product_name are required" });
    }
    console.log("Start ROBUST orchestration with SEGMENTATION for:", { productName });
    const imgResp = await fetch(imageUrl);
    if (!imgResp.ok) throw new Error(`Failed to fetch vendor image: ${imgResp.status}`);
    const imgBuf = Buffer.from(await imgResp.arrayBuffer());
    const imageBase64 = imgBuf.toString("base64");

    // Step 1: Get metadata (unchanged)
    let visionData;
    try {
        visionData = await callVisionGenerate(imageBase64, productName);
    } catch (err) {
        console.warn("Vision metadata extraction failed, using defaults.", err.message);
        visionData = { product_name: productName, category: "Other", description: "", price: 0, stock: 0 };
    }

    // Step 2: Generate mask using the new, reliable model
    let maskBase64;
    try {
        maskBase64 = await callSegmentationModel(imageBase64);
    } catch (err) {
        console.error("CRITICAL: Segmentation mask generation failed.", err);
        return res.status(502).json({ error: "mask_generation_failed", details: err.message, vision: visionData });
    }
    
    // Step 3: Inpaint using the guaranteed-valid mask (unchanged)
    const backgroundPrompt = `A professional e-commerce background for '${visionData.product_name}'. Clean, studio lighting, aesthetic, 4k, photorealistic.`;
    const enhancedImages = await callInpaintingWithMask(imageBase64, maskBase64, backgroundPrompt, MAX_IMAGES);
    
    // ... (Uploading and response logic is the same) ...

  } catch (err) {
    console.error("Orchestration fatal error:", err?.stack || String(err));
    return res.status(500).json({ error: "orchestration_failed", details: err.message });
  }
});

// --------- graceful shutdown ----------
const server = app.listen(PORT, () => {
  console.log(`vendor-ai-worker listening on port ${PORT}`);
});
process.on("SIGTERM", () => {
  console.info("SIGTERM received, closing server");
  server.close(() => process.exit(0));
});
process.on("SIGINT", () => {
  console.info("SIGINT received, closing server");
  server.close(() => process.exit(0));
});

// --- OMITTED FUNCTIONS FOR BREVITY (COPY FROM PREVIOUS FULL CODE) ---
// Please ensure these functions are present in your final file.
// async function getAccessToken() { ... }
// function tryParseJson(str) { ... }
// async function uploadBase64ToSupabase(base64OrDataUri, pathFilename) { ... }
// async function callVisionGenerate(imageBase64, productName) { ... }
// async function callInpaintingWithMask(imageBase64, maskBase64, prompt, sampleCount) { ... }